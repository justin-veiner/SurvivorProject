{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7dbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import urllib.parse\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import re\n",
    "tqdm.pandas()\n",
    "\n",
    "NUM_SEASONS = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e5bd6",
   "metadata": {},
   "source": [
    "## Contestant Table\n",
    "\n",
    "Pull contestant info from https://en.wikipedia.org/wiki/List_of_Survivor_(American_TV_series)_contestants\n",
    "\n",
    "Get contestant name, age, hometown, profession, season, and placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b4671d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_Survivor_(American_TV_series)_contestants\"\n",
    "table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "response=requests.get(wiki_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "tables = soup.findAll(\"table\", class_='wikitable')\n",
    "contestant_table = pd.read_html(str(tables))\n",
    "contestant_table = pd.concat(contestant_table, axis = 0).reset_index(drop=True)\n",
    "contestant_table.columns = contestant_table.columns.str.lower()\n",
    "contestant_table = contestant_table.rename(columns={'name':'contestant_name'})\n",
    "contestant_table = contestant_table.rename(columns={'season':'num_season'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f43bb",
   "metadata": {},
   "source": [
    "Label season number each contestant was on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55e47c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = contestant_table.num_season.unique()\n",
    "contestant_table[\"num_season\"] = contestant_table.apply(lambda x: np.where(seasons == x.num_season)[0][0]+1,axis=1)\n",
    "contestant_table = contestant_table[contestant_table.num_season <= NUM_SEASONS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f62e65",
   "metadata": {},
   "source": [
    "Fix contestant names by taking their alias instead of their given name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496fcf2",
   "metadata": {},
   "source": [
    "Convert contestant placement (string) to numerical placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb689844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_name(x):\n",
    "    if '\"' in x:\n",
    "        return x[x.find('\"'):].replace('\"',\"\").strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eca5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finish(f):\n",
    "    if str(f) == \"nan\":\n",
    "        return np.nan\n",
    "    if f.lower() == \"winner\":\n",
    "        return 1\n",
    "    if f.lower() == \"2nd runner-up\":\n",
    "        return 3\n",
    "    if f.lower() == \"runner-up\" or f.lower() == \"co-runner up\":\n",
    "        return 2\n",
    "    return int(f[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18bf9b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 785/785 [00:00<00:00, 23830.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 785/785 [00:00<00:00, 55960.17it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table[\"finish\"] = contestant_table.progress_apply(lambda x:get_finish(x.finish),axis = 1)\n",
    "contestant_table[\"contestant_name\"] = contestant_table.progress_apply(lambda x:fix_name(x.contestant_name),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4cd4e1",
   "metadata": {},
   "source": [
    "MANUAL CLEANUP: manually fix names to match those on https://survivor.fandom.com/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8dd9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_fixes = {\n",
    "    'Jonny Fairplay Dalton':'Jon Dalton',\n",
    "    'J.P. Palyok': 'John Palyok',\n",
    "    'Bubba Sampson': 'Travis Sampson',\n",
    "    'Sarge Masters': 'Lea Masters',\n",
    "    'Mikey B Bortone': 'Mikey Bortone',\n",
    "    'J.T. Thomas, Jr.' : 'J.T. Thomas',\n",
    "    'Papa Bear Caruso' : 'Mark Caruso',\n",
    "    'Rodney Lavoie, Jr.' : 'Rodney Lavoie',\n",
    "    'Joe Del Campo':'Joe del Campo',\n",
    "    'The Wardog DaSilva':'Wardog DaSilva',\n",
    "    'Amber Brkich':'Amber Mariano',\n",
    "    'Kim Spradlin':'Kim Spradlin-Wolfe',\n",
    "    'Candice Woodcock':'Candice Cody',\n",
    "    'Wendy Jo DeSmidt-Kohlhoff':'Wendy DeSmidt-Kohlhoff',\n",
    "    'Christine Shields-Markoski':'Christine Shields Markoski',\n",
    "    'Flicka Smith' : 'Jessica Smith',\n",
    "    'Mad Dog Hershey' : 'Maralyn Hershey',\n",
    "    'Taylor Lee Stocker' : 'Taylor Stocker'\n",
    "}\n",
    "\n",
    "contestant_table = contestant_table.replace({'contestant_name':name_fixes})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3a257",
   "metadata": {},
   "source": [
    "Get the gender of each contestant. We loop through the pages of male contestants and store all their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7098b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://survivor.fandom.com/wiki/Category:Male_Contestants\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "pages = soup.find(class_=\"category-page__pagination\")\n",
    "pagination_links = pages.findAll(\"a\",href=True)\n",
    "males = []\n",
    "done = False\n",
    "while not done:\n",
    "    mlinks = soup.findAll(class_=\"category-page__member-link\") #link of male contestant\n",
    "    \n",
    "    for mlink in mlinks:\n",
    "        males.append(mlink['title']) #male contestant's name\n",
    "    for link in pagination_links: #loop through pagination links to find the \"Next\" link\n",
    "        label = ''\n",
    "        try:\n",
    "            label = link.find('span').text\n",
    "        except:\n",
    "            label = ''\n",
    "        \n",
    "        if label == 'Next': \n",
    "            next_link = link['href']\n",
    "            break\n",
    "    \n",
    "    if label == 'Next': #if not at last page, get next batch of names through next link\n",
    "        response = requests.get(next_link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        pages = soup.find(class_=\"category-page__pagination\")\n",
    "        \n",
    "        pagination_links = pages.findAll(\"a\",href=True)\n",
    "    else: #label will be \"Previous\" and we have accessed all the pages\n",
    "        done = True\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71928a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table.loc[contestant_table.contestant_name.isin(males),\"gender\"] = 'M' #male contestants\n",
    "contestant_table.loc[contestant_table.gender != 'M', 'gender'] = 'F' #female contestants\n",
    "contestant_table.loc[contestant_table.contestant_name == 'Evvie Jagoda', 'gender'] = 'N' #non-binary contestants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69e56625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ethnicity_link(link):\n",
    "    return re.sub('-','_', link).lower()[len('/wiki/category:'):len(link)-len('_contestants')]\n",
    "\n",
    "url = \"https://survivor.fandom.com/wiki/Category:Contestants_by_Ethnicity\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "pages = soup.find_all(class_ = \"category-page__member-link\",href=True) #get ethnicity categories\n",
    "start_url = \"https://survivor.fandom.com\"\n",
    "contestants_by_ethnicity = {clean_ethnicity_link(page['href']):[] for page in pages}\n",
    "for page in pages:\n",
    "    response = requests.get(start_url+page[\"href\"])\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    contestant_list = []\n",
    "    contestant_links = soup.findAll(class_=\"category-page__member-link\")\n",
    "    for c_link in contestant_links:\n",
    "        contestant_list.append(c_link[\"title\"])\n",
    "    contestants_by_ethnicity[clean_ethnicity_link(page['href'])] = contestant_list\n",
    "    \n",
    "    \n",
    "for ethnicity, eth_list in contestants_by_ethnicity.items():\n",
    "    contestant_table[ethnicity] = contestant_table.apply(lambda x: int(x['contestant_name'] in eth_list), axis = 1)\n",
    "    \n",
    "contestant_table['poc'] = contestant_table['african_american'] | contestant_table['asian_american'] | contestant_table['latin_american']\n",
    "\n",
    "jewish = ['Ethan Zohn','Shawn Cohen','Eliza Orlins','Caryn Groedel','Jonathan Penner','Charlie Herschel'\n",
    "          ,'Corinne Kaplan','Stephen Fishbach','John Cochran','R.C.Saint-Amour','David Samson','Garrett Adelstein',\n",
    "          'Max Dawson','Adam Klein','Hannah Shapiro','Zeke Smith','Mike Zahalsky','Jacob Derwin',\n",
    "          'Julie Rosenberg','Ronnie Bardah','Jason Linden','Sydney Segal','Tiffany Seely','Evvie Jagoda',\n",
    "          'Liana Wallace','Zach Wurtenberger','Lindsay Dolashewich']\n",
    "muslim = ['Ibrehem Rahman', 'Natalia Azoqa', 'Naseer Muttalif', 'Omar Zaheer']\n",
    "\n",
    "\n",
    "for religion in ['jewish', 'muslim']:\n",
    "    contestant_table[religion] = contestant_table.apply(lambda x: int(x['contestant_name'] in eval(religion)), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2421ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://survivor.fandom.com/wiki/Category:LGBT_Contestants\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "lgbt = []\n",
    "pages = soup.findAll(class_ = \"category-page__member-link\", href=True)\n",
    "for page in pages:\n",
    "    lgbt.append(page[\"title\"])\n",
    "    \n",
    "contestant_table[\"lgbt\"] = contestant_table.apply(lambda x: int(x['contestant_name'] in lgbt), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d959e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 785/785 [00:00<00:00, 49795.51it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table['hometown'] = contestant_table.progress_apply(lambda x: \", \".join(x['hometown'].split(',')[0:2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05764d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_and_provinces = {\n",
    "\"Alabama\": \"AL\",\n",
    "\"Alaska\": \"AK\",\n",
    "\"Arizona\": \"AZ\",\n",
    "\"Arkansas\": \"AR\",\n",
    "\"California\": \"CA\",\n",
    "\"Colorado\": \"CO\",\n",
    "\"Connecticut\": \"CT\",\n",
    "\"Delaware\": \"DE\",\n",
    "\"Florida\": \"FL\",\n",
    "\"Georgia\": \"GA\",\n",
    "\"Hawaii\": \"HI\",\n",
    "\"Idaho\": \"ID\",\n",
    "\"Illinois\": \"IL\",\n",
    "\"Indiana\": \"IN\",\n",
    "\"Iowa\": \"IA\",\n",
    "\"Kansas\": \"KS\",\n",
    "\"Kentucky\": \"KY\",\n",
    "\"Louisiana\": \"LA\",\n",
    "\"Maine\": \"ME\",\n",
    "\"Maryland\": \"MD\",\n",
    "\"Massachusetts\": \"MA\",\n",
    "\"Michigan\": \"MI\",\n",
    "\"Minnesota\": \"MN\",\n",
    "\"Mississippi\": \"MS\",\n",
    "\"Missouri\": \"MO\",\n",
    "\"Montana\": \"MT\",\n",
    "\"Nebraska\": \"NE\",\n",
    "\"Nevada\": \"NV\",\n",
    "\"New Hampshire\": \"NH\",\n",
    "\"New Jersey\": \"NJ\",\n",
    "\"New Mexico\": \"NM\",\n",
    "\"New York\": \"NY\",\n",
    "\"North Carolina\": \"NC\",\n",
    "\"North Dakota\": \"ND\",\n",
    "\"Ohio\": \"OH\",\n",
    "\"Oklahoma\": \"OK\",\n",
    "\"Oregon\": \"OR\",\n",
    "\"Pennsylvania\": \"PA\",\n",
    "\"Rhode Island\": \"RI\",\n",
    "\"South Carolina\": \"SC\",\n",
    "\"South Dakota\": \"SD\",\n",
    "\"Tennessee\": \"TN\",\n",
    "\"Texas\": \"TX\",\n",
    "\"Utah\": \"UT\",\n",
    "\"Vermont\": \"VT\",\n",
    "\"Virginia\": \"VA\",\n",
    "\"Washington\": \"WA\",\n",
    "\"West Virginia\": \"WV\",\n",
    "\"Wisconsin\": \"WI\",\n",
    "\"Wyoming\": \"WY\",\n",
    "\"District of Columbia\": \"DC\",\n",
    "\"American Samoa\": \"AS\",\n",
    "\"Guam\": \"GU\",\n",
    "\"Northern Mariana Islands\": \"MP\",\n",
    "\"Puerto Rico\": \"PR\",\n",
    "\"United States Minor Outlying Islands\": \"UM\",\n",
    "\"U.S. Virgin Islands\": \"VI\",\n",
    "\"Ontario\":\"ON\",\n",
    "\"Quebec\":\"QC\",\n",
    "\"Saskatchewan\":\"SK\",\n",
    "\"Alberta\":\"AB\",\n",
    "\"British Columbia\":\"BC\",\n",
    "\"Manitoba\":\"MB\",\n",
    "\"New Brunswick\":\"NB\",\n",
    "\"Nova Scotia\":\"NS\",\n",
    "\"Newfoundland and Labrador\":\"NL\",\n",
    "\"Prince Edward Island\":\"PE\",\n",
    "\"Nunavut\":\"NU\",\n",
    "\"Northwest Territories\":\"NT\",\n",
    "\"Yukon\":\"YT\"\n",
    "}\n",
    "\n",
    "states_and_provinces_abbr = dict(map(reversed, states_and_provinces.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91b9d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_and_country(x):\n",
    "    ht = x['hometown']\n",
    "    state = ht.split(', ')[-1].strip()\n",
    "    country = \"US\"\n",
    "    if len(state) == 2:\n",
    "        state = states_and_provinces_abbr[state]\n",
    "    if state in list(states_and_provinces.keys())[-13:]:\n",
    "        country = \"CA\"\n",
    "    return state, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b507fa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 785/785 [00:00<00:00, 2315.71it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table[['state','country']] = contestant_table.progress_apply(lambda x : pd.Series(get_state_and_country(x)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "148cfa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table[\"num_appearance\"] = contestant_table.groupby(\"contestant_name\").rank()[\"num_season\"].to_numpy().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9c50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_birthdate(name):\n",
    "    url = \"https://survivor.fandom.com/wiki/\" + name.replace(\" \",\"_\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    bdate = \"\"\n",
    "    try:\n",
    "        bdate = pd.to_datetime(soup.find(class_=\"bday\").text.split('[')[0])\n",
    "    except:\n",
    "        try:\n",
    "            bdate = pd.to_datetime(soup.find(class_=\"pi-item pi-data pi-item-spacing pi-border-color\").find(class_=\"pi-data-value pi-font\").text.split('[')[0])\n",
    "        except:\n",
    "            print(name)\n",
    "    return bdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "170bf670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 785/785 [06:45<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table[\"birthdate\"] = contestant_table.progress_apply(lambda x:get_birthdate(x.contestant_name),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "398a255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = ['Survivor: Borneo', 'Survivor: The Australian Outback',\n",
    "       'Survivor: Africa', 'Survivor: Marquesas', 'Survivor: Thailand',\n",
    "       'Survivor: The Amazon', 'Survivor: Pearl Islands',\n",
    "       'Survivor: All-Stars', 'Survivor: Vanuatu', 'Survivor: Palau',\n",
    "       'Survivor: Guatemala', 'Survivor: Panama',\n",
    "       'Survivor: Cook Islands', 'Survivor: Fiji', 'Survivor: China',\n",
    "       'Survivor: Micronesia', 'Survivor: Gabon', 'Survivor: Tocantins',\n",
    "       'Survivor: Samoa', 'Survivor: Heroes vs. Villains',\n",
    "       'Survivor: Nicaragua', 'Survivor: Redemption Island',\n",
    "       'Survivor: South Pacific', 'Survivor: One World',\n",
    "       'Survivor: Philippines', 'Survivor: Caramoan',\n",
    "       'Survivor: Blood vs. Water', 'Survivor: Cagayan',\n",
    "       'Survivor: San Juan del Sur', 'Survivor: Worlds Apart',\n",
    "       'Survivor: Cambodia', 'Survivor: Kaôh Rōng',\n",
    "       'Survivor: Millennials vs. Gen X', 'Survivor: Game Changers',\n",
    "       'Survivor: Heroes vs. Healers vs. Hustlers',\n",
    "       'Survivor: Ghost Island', 'Survivor: David vs. Goliath',\n",
    "       'Survivor: Edge of Extinction', 'Survivor: Island of the Idols',\n",
    "       'Survivor: Winners at War', 'Survivor 41', 'Survivor 42', 'Survivor 43']\n",
    "\n",
    "merged_tribes = ['Rattana', 'Barramundi', 'Moto Maji', 'Soliantu', 'Chuay Jai',\n",
    "       'Jacaré', 'Balboa', 'Chaboga Mogo', 'Alinta', 'Koror', 'Xhakúm',\n",
    "       'Gitanos', 'Aitutonga', 'Bula Bula', 'Hae Da Fung', 'Dabu',\n",
    "       'Nobag', 'Forza', 'Aiga', 'Yin Yang', 'Libertad', 'Murlonio',\n",
    "       'Te Tuna', 'Tikiano', 'Dangrayne', 'Enil Edam', 'Kasama',\n",
    "       'Solarrion', 'Huyopa', 'Merica', 'Orkun', 'Dara', 'Vinaka',\n",
    "       'Maku Maku', 'Solewa', 'Lavita', 'Kalokalo', 'Vata', 'Lumuwaku',\n",
    "       'Koru', 'Viakana', 'Kula Kula', 'Gaia']\n",
    "\n",
    "num_merge = [10, 10, 10, 10,  8, 10, 10,  9, 10,  9, 10, 10,  9, 10, 10, 10,  9,\n",
    "       10, 12, 10, 12, 12, 12, 12, 11, 12, 11, 11, 12, 12, 13, 11, 13, 13,\n",
    "       12, 13, 13, 14, 13, 13, 12, 12, 12]\n",
    "\n",
    "day_merge = [20, 20, 20, 20, 25, 19, 21, 26, 20, 22, 18, 16, 25, 22, 20, 22, 27,\n",
    "       19, 19, 25, 19, 19, 19, 17, 17, 20, 19, 17, 16, 17, 17, 17, 21, 19,\n",
    "       17, 20, 18, 17, 20, 19, 12, 12, 13]\n",
    "\n",
    "num_jury = [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  9,  9,  7,  8,  7,\n",
    "        7,  9,  9,  9,  9,  9,  9,  8,  8,  8,  9,  8,  8, 10,  8, 10, 10,\n",
    "        8, 10, 10, 13, 10, 16,  8,  8, 8]\n",
    "\n",
    "num_ftc = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3,\n",
    "       3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
    "\n",
    "num_swaps = [0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 0, 0, 0, 1, 0,\n",
    "       0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbbf9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = pd.DataFrame({\n",
    "    'num_season': list(range(1, NUM_SEASONS + 1)),\n",
    "    'season' : seasons,\n",
    "    'merged_tribe' : merged_tribes,\n",
    "    'num_merge' : num_merge,\n",
    "    'day_merge' : day_merge,\n",
    "    'num_jury' : num_jury,\n",
    "    'num_ftc' : num_ftc,\n",
    "    'num_swaps' : num_swaps\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbbe1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table['num_contestants'] = season_table.apply(lambda x:len(contestant_table[contestant_table.num_season == x['num_season']]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43dcc6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def made_merge(x):\n",
    "    if x.finish <= season_table.loc[x.num_season-1, \"num_merge\"]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def made_ftc(x):\n",
    "    if x.finish <= season_table.loc[x.num_season-1, \"num_ftc\"]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def made_jury(x):\n",
    "    if x.finish > season_table.loc[x.num_season-1, \"num_ftc\"] and x.finish <=season_table.loc[x.num_season-1, \"num_ftc\"].any()+season_table.loc[x.num_season-1, \"num_jury\"]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "contestant_table['merge'] = contestant_table.apply(lambda x:made_merge(x), axis = 1)\n",
    "contestant_table['jury'] = contestant_table.apply(lambda x: made_jury(x), axis = 1)\n",
    "contestant_table['ftc'] = contestant_table.apply(lambda x:made_ftc(x), axis = 1)\n",
    "\n",
    "jury_modifications = [('Wendy Diaz', 38, 0), ('Sandra Diaz-Twine', 40, 0), ('Reem Daly', 38, 1), ('Amber Mariano', 40, 1)]\n",
    "\n",
    "for name, ns, j in jury_modifications:\n",
    "    contestant_table.loc[(contestant_table.contestant_name == name) & (contestant_table.num_season == ns), 'jury'] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4876a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:27<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "votes_list = []\n",
    "season_list = []\n",
    "finish_list = []\n",
    "for row in tqdm(range(NUM_SEASONS)):\n",
    "    season_name = season_table.loc[row,\"season\"]\n",
    "    num_contestants = season_table.loc[row,\"num_contestants\"]\n",
    "    num_season = season_table.loc[row,\"num_season\"]\n",
    "    url = \"https://survivor.fandom.com/wiki/\"+season_name.replace(\" \",\"_\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table_index = 0\n",
    "    if num_season == 31:\n",
    "        table_index = 1\n",
    "    rows = soup.findAll(class_=\"wikitable\")[table_index].tbody.findAll(\"tr\")\n",
    "    finish = 1\n",
    "    i = 1\n",
    "    while finish <= num_contestants:\n",
    "        votes = -1\n",
    "        try:\n",
    "            votes = int(rows[-i].findAll(\"td\")[-1].text)\n",
    "        except:\n",
    "            votes = -1\n",
    "        if votes != -1:\n",
    "            votes_list.append(votes)\n",
    "            season_list.append(num_season)\n",
    "            finish_list.append(finish)\n",
    "            finish += 1\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "votes_df = pd.DataFrame({\"num_season\":season_list, \"finish\":finish_list, \"votes_against\":votes_list})\n",
    "contestant_table = pd.merge(contestant_table, votes_df, on=[\"num_season\",\"finish\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d2c7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table[\"redemption_island\"] = 0\n",
    "season_table.loc[[21,22,26],\"redemption_island\"] = 1\n",
    "season_table[\"edge_of_extinction\"] = 0\n",
    "season_table.loc[[37,39],\"edge_of_extinction\"] = 1\n",
    "season_table[\"num_days\"] = 39\n",
    "season_table.loc[1,\"num_days\"] = 42\n",
    "season_table.loc[[40,41, 42],\"num_days\"] = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed1565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demographic_counts = pd.DataFrame(contestant_table.groupby([\"num_season\"]).sum()[[\"african_american\",\"asian_american\",\"latin_american\",\"poc\",\"lgbt\",\"jewish\",\"muslim\"]],\n",
    "                                                            index=season_table.num_season)\n",
    "\n",
    "season_table = pd.merge(season_table, total_demographic_counts, on=['num_season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da4afbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table['num_boot'] = season_table.loc[contestant_table.num_season - 1,\"num_contestants\"].reset_index(drop = True) - contestant_table['finish'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6427c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://survivor.fandom.com/wiki/Tribe\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "table = soup.findAll(\"table\",class_='wikitable')[1]\n",
    "tribe_data = pd.read_html(str(table))[0]\n",
    "tribe_list = np.ravel(tribe_data[tribe_data.columns[1:]].loc[:NUM_SEASONS - 1,:].to_numpy())\n",
    "tribe_list = [tribe for tribe in tribe_list if str(tribe) != 'nan']\n",
    "tribe_list.append(\"David\")\n",
    "tribe_list.append(\"Vuku\")\n",
    "tribe_list.append(\"Goliath\")\n",
    "tribe_list.append(\"Jabeni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bca6dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 43/43 [00:26<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "tlist = [[],[],[]]\n",
    "slist = []\n",
    "flist = []\n",
    "for row in tqdm(range(NUM_SEASONS)):    \n",
    "    season_name = season_table.loc[row,\"season\"]\n",
    "    num_contestants = season_table.loc[row,\"num_contestants\"]\n",
    "    num_season = season_table.loc[row,\"num_season\"]\n",
    "    num_swaps = season_table.loc[row,\"num_swaps\"]\n",
    "    url = \"https://survivor.fandom.com/wiki/\"+season_name.replace(\" \",\"_\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table_index = 0\n",
    "    if num_season == 31:\n",
    "         table_index = 1\n",
    "    rows = soup.findAll(class_=\"wikitable\")[table_index].tbody.findAll(\"tr\")\n",
    "    finish = 1\n",
    "    i = 1\n",
    "    while finish <= num_contestants:\n",
    "        tribes = [np.nan, np.nan, np.nan]\n",
    "        votes = -1\n",
    "        try:\n",
    "            votes = int(rows[-i].findAll(\"td\")[-1].text)\n",
    "        except:\n",
    "            votes = -1\n",
    "        if votes != -1:\n",
    "            #tribe = rows[-i].findAll(\"td\")[2].text.strip()\n",
    "            for j in range(num_swaps + 1):\n",
    "                tribe = rows[-i].findAll(\"td\")[2+j].text.strip()\n",
    "                if tribe in tribe_list:\n",
    "                    tribes[j] = tribe\n",
    "            tlist[0].append(tribes[0])\n",
    "            tlist[1].append(tribes[1])\n",
    "            tlist[2].append(tribes[2])\n",
    "            slist.append(num_season)\n",
    "            flist.append(finish)\n",
    "            finish += 1\n",
    "\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd669f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_contestant_df = pd.DataFrame({'num_season':slist, 'finish':flist, 'tribe1':tlist[0], 'tribe2':tlist[1], 'tribe3':tlist[2]})\n",
    "contestant_table = pd.merge(contestant_table, tribe_contestant_df, how='left', on=['num_season','finish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c458bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_table1 = pd.DataFrame(contestant_table[[\"num_season\",\"tribe1\"]].drop_duplicates().to_numpy(),columns=[\"num_season\",\"tribe\"])\n",
    "tribe_table1[\"iter_num\"] = 1\n",
    "tribe_table1[\"num_contestants\"] = tribe_table1.apply(lambda x:\n",
    "                                                  len(contestant_table[(contestant_table.num_season == x.num_season)&\n",
    "                                                                      (contestant_table.tribe1 == x.tribe)]), axis=1)\n",
    "\n",
    "tribe_table2 = pd.DataFrame(contestant_table[[\"num_season\",\"tribe2\"]].drop_duplicates().to_numpy(),columns=[\"num_season\",\"tribe\"])\n",
    "tribe_table2['iter_num'] = 2\n",
    "tribe_table2[\"num_contestants\"] = tribe_table2.apply(lambda x:\n",
    "                                                  len(contestant_table[(contestant_table.num_season == x.num_season)&\n",
    "                                                                      (contestant_table.tribe2 == x.tribe)]), axis=1)\n",
    "tribe_table2 = tribe_table2.dropna()\n",
    "tribe_table3 = pd.DataFrame(contestant_table[[\"num_season\",\"tribe3\"]].drop_duplicates().to_numpy(),columns=[\"num_season\",\"tribe\"])\n",
    "tribe_table3['iter_num'] = 3\n",
    "tribe_table3[\"num_contestants\"] = tribe_table3.apply(lambda x:\n",
    "                                                  len(contestant_table[(contestant_table.num_season == x.num_season)&\n",
    "                                                                      (contestant_table.tribe3 == x.tribe)]), axis=1)\n",
    "tribe_table3 = tribe_table3.dropna()\n",
    "\n",
    "\n",
    "tribe_table = pd.concat([tribe_table1, tribe_table2, tribe_table3],ignore_index=True)\n",
    "tribe_table = tribe_table.sort_values([\"num_season\",\"iter_num\"])\n",
    "tribe_table['merge'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c13fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_contestant_table = pd.concat([\n",
    "    contestant_table.drop(['tribe2', 'tribe3'], axis = 1).rename(columns={'tribe1':'tribe'}).assign(iter_num = 1),\n",
    "    contestant_table.drop(['tribe1', 'tribe3'], axis = 1).rename(columns={'tribe2':'tribe'}).assign(iter_num = 2),\n",
    "    contestant_table.drop(['tribe1', 'tribe2'], axis = 1).rename(columns={'tribe3':'tribe'}).assign(iter_num = 3)\n",
    "]).dropna(subset = ['tribe'])\n",
    "\n",
    "tribe_demos = exp_contestant_table.groupby(['num_season','tribe','iter_num']).sum().reset_index()\n",
    "tribe_table = pd.merge(tribe_table, tribe_demos[['num_season','tribe','iter_num','african_american','asian_american',\n",
    "                                                'latin_american','poc','jewish','muslim','lgbt']], how='left',\n",
    "                      on=['num_season','tribe','iter_num'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0cf308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_table['male'] = tribe_table.apply(lambda x:len(expanded_contestant_table[(expanded_contestant_table.num_season == x.num_season)\n",
    "                                                                         & (expanded_contestant_table.tribe == x.tribe)\n",
    "                                                                         & (expanded_contestant_table.iter_num == x.iter_num)\n",
    "                                                                         & (expanded_contestant_table.gender == 'M')]), axis = 1)\n",
    "tribe_table['female'] = tribe_table.apply(lambda x:len(expanded_contestant_table[(expanded_contestant_table.num_season == x.num_season)\n",
    "                                                                         & (expanded_contestant_table.tribe == x.tribe)\n",
    "                                                                         & (expanded_contestant_table.iter_num == x.iter_num)\n",
    "                                                                         & (expanded_contestant_table.gender == 'F')]), axis= 1)\n",
    "tribe_table['non_binary'] = tribe_table.apply(lambda x:len(expanded_contestant_table[(expanded_contestant_table.num_season == x.num_season)\n",
    "                                                                         & (expanded_contestant_table.tribe == x.tribe)\n",
    "                                                                         & (expanded_contestant_table.iter_num == x.iter_num)\n",
    "                                                                         & (expanded_contestant_table.gender == 'N')]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd38b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tribe_table = pd.DataFrame({\n",
    "    \"num_season\":season_table.num_season.unique(),\n",
    "    \"tribe\": season_table.merged_tribe.unique(),\n",
    "    \"iter_num\": np.zeros(len(season_table.index)),\n",
    "    \"merge\": np.ones(len(season_table.index)),\n",
    "    \"num_contestants\": season_table.num_merge\n",
    "})\n",
    "\n",
    "merge_demos = contestant_table[contestant_table['merge'] == 1].groupby('num_season').sum().reset_index()\n",
    "merged_tribe_table = pd.merge(merged_tribe_table, merge_demos[['num_season','african_american','asian_american',\n",
    "                                                'latin_american','poc','jewish','muslim','lgbt']], how='left',\n",
    "                                                  on=['num_season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddbe5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tribe_table['male'] = merged_tribe_table.apply(lambda x:len(contestant_table[(contestant_table.num_season == x.num_season)\n",
    "                                                                         & (contestant_table['merge'] == 1)\n",
    "                                                                         & (contestant_table.gender == 'M')]), axis = 1)\n",
    "merged_tribe_table['female'] = merged_tribe_table.apply(lambda x:len(contestant_table[(contestant_table.num_season == x.num_season)\n",
    "                                                                         & (contestant_table['merge'] == 1)\n",
    "                                                                         & (contestant_table.gender == 'F')]), axis = 1)\n",
    "merged_tribe_table['non_binary'] = merged_tribe_table.apply(lambda x:len(contestant_table[(contestant_table.num_season == x.num_season)\n",
    "                                                                         & (contestant_table['merge'] == 1)\n",
    "                                                                         & (contestant_table.gender == 'N')]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef1d6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_table = pd.concat([tribe_table, merged_tribe_table], ignore_index = True)\n",
    "tribe_table = tribe_table.sort_values(by=[\"num_season\",\"merge\",\"iter_num\"], ascending=[True,True,True])\n",
    "tribe_table = tribe_table.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc1e3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tribe_color(x):\n",
    "    if x['tribe'] == 'David' or x['tribe'] == 'Vuku':\n",
    "        return 'Blue/Teal'\n",
    "    if x['tribe'] == 'Goliath' or x['tribe'] == 'Jabeni':\n",
    "        return 'Purple'\n",
    "    return tribe_data.columns[np.where(tribe_data.isin([x['tribe']]).any())[0][0]][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdfa3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 225/225 [00:00<00:00, 618.82it/s]\n"
     ]
    }
   ],
   "source": [
    "tribe_table['color'] = tribe_table.progress_apply(lambda x: get_tribe_color(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e3fefcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tribe_table = tribe_table.dropna(subset = ['tribe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00cc55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quit_and_evac(row):\n",
    "    name = row[\"contestant_name\"]\n",
    "    num_appearance = row[\"num_appearance\"]\n",
    "    url = \"https://survivor.fandom.com/wiki/\"+\"_\".join(name.split(\" \"))\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    response.close()\n",
    "    tables = soup.findAll(class_='wikitable')\n",
    "    quit, evac = 0, 0\n",
    "    try:\n",
    "        status1 = tables[num_appearance-1].findAll(\"td\")[-1].text.strip().split(\",\")[0]\n",
    "        status2 = tables[num_appearance-1].findAll(\"td\")[-3].text.strip().split(\",\")[0]\n",
    "        if status1 == 'Quit' or status2 == 'Quit':\n",
    "            quit = 1\n",
    "        if status1 == 'Evacuated' or status2 == 'Evacuated':\n",
    "            evac = 1\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return quit, evac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77f9f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 785/785 [05:45<00:00,  2.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 785/785 [06:27<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table[[\"quit\",\"evac\"]] = contestant_table.progress_apply(lambda x: pd.Series(get_quit_and_evac(x)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a30806ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table[\"num_quits\"] = contestant_table[[\"num_season\",\"quit\",\"evac\"]].groupby(\"num_season\").sum()[\"quit\"].reset_index(drop=True)\n",
    "season_table[\"num_evacs\"] = contestant_table[[\"num_season\",\"quit\",\"evac\"]].groupby(\"num_season\").sum()[\"evac\"].reset_index(drop=True)\n",
    "contestant_table[\"ejected\"] = 0\n",
    "contestant_table.loc[contestant_table.contestant_name==\"Dan Spilo\",\"ejected\"] = 1\n",
    "contestant_table.loc[(contestant_table.contestant_name == 'Jack Nichting') & (contestant_table.num_season == 39), 'jury'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47474501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jury_votes(row):\n",
    "    name = row[\"contestant_name\"]\n",
    "    num_appearance = row[\"num_appearance\"]\n",
    "    ftc = int(row[\"ftc\"])\n",
    "    if ftc == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    url = \"https://survivor.fandom.com/wiki/\"+\"_\".join(name.split(\" \"))\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    response.close()\n",
    "    tables = soup.findAll(class_='wikitable')\n",
    "    table = tables[int(num_appearance) - 1]\n",
    "    votes = table.findAll(\"td\")[-2].text.strip().split(',')\n",
    "    if votes == ['-']:\n",
    "        return 0\n",
    "    return len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce03f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table['fmc'] = 0\n",
    "contestant_table.loc[(contestant_table.num_season >= 35) & (contestant_table.finish == 4), 'fmc'] = 1\n",
    "fmcs = [('Bobby Jon Drinkard', 10), ('Jennifer Lyon', 10), ('Cirie Fields', 12), ('Becky Lee', 13), ('Matty Whitmore', 17),\n",
    "       ('Rodney Lavoie', 30), ('Cydney Gillon', 32)]\n",
    "for name, ns in fmcs:\n",
    "    contestant_table.loc[(contestant_table.contestant_name == name) & (contestant_table.num_season == ns), 'fmc'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b2d8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 785/785 [01:04<00:00, 12.13it/s]\n"
     ]
    }
   ],
   "source": [
    "contestant_table[\"num_jury_votes\"] = contestant_table.progress_apply(lambda x:get_jury_votes(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23e31273",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table['normalized_finish'] = contestant_table.apply(lambda x : 1 - x.finish / season_table.loc[season_table.num_season == x.num_season, 'num_contestants'].iloc[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "742e8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table['winner'] = contestant_table.loc[contestant_table.finish == 1, 'contestant_name'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bd6c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table.to_csv(\"contestant_table.csv\", index=False)\n",
    "season_table.to_csv(\"season_table.csv\", index=False)\n",
    "tribe_table.to_csv(\"tribe_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "121681b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table.to_pickle('contestant_table.pkl')\n",
    "season_table.to_pickle('season_table.pkl')\n",
    "tribe_table.to_pickle('tribe_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cca8d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "contestant_table = pd.read_csv('contestant_table.csv')\n",
    "season_table = pd.read_csv('season_table.csv')\n",
    "tribe_table = pd.read_csv('tribe_table.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
